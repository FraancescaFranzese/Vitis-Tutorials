{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdf2452-4c3b-4ce0-b019-cbe980967a1c",
   "metadata": {},
   "source": [
    "# Testbench for `mnist_app()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233a3b7-37d3-4c5d-b492-faade3ded16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2024, Advanced Micro Devices, Inc. All rights reserved.\n",
    "# SPDX-License-Identifier: MIT\n",
    "#\n",
    "# Author: Mark Rollins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e0796-0306-4ce9-9a92-598027c75f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc7e83-3fd0-4fd0-99b5-7938816f0df2",
   "metadata": {},
   "source": [
    "## Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49534849-a68e-4aed-82d8-4e71837fe541",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28,28,1),name=\"input\")\n",
    "x1 = layers.Conv2D(filters=16,kernel_size=3,activation=\"relu\",name=\"conv2d_w1\")(inputs)\n",
    "x2 = layers.MaxPooling2D(pool_size=2,name=\"max_pooling2d_w2\")(x1)\n",
    "x3 = layers.Conv2D(filters=64,kernel_size=3,activation=\"relu\",name=\"conv2d_w3\")(x2)\n",
    "x4 = layers.MaxPooling2D(pool_size=2,name=\"max_pooling2d_w4\")(x3)\n",
    "x5 = layers.Conv2D(filters=128,kernel_size=3,activation=\"relu\",name=\"conv2d_w5\")(x4)\n",
    "x6 = layers.Flatten()(x5)\n",
    "outputs = layers.Dense(10,activation=\"softmax\")(x6)\n",
    "model = keras.Model(inputs=inputs,outputs=outputs,name=\"ConvNet\")\n",
    "w1_taps = ((np.loadtxt('../conv2d_w1/taps_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w1_taps = np.reshape(w1_taps,(3,3,1,16))\n",
    "w1_bias = ((np.loadtxt('../conv2d_w1/bias_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w3_taps = ((np.loadtxt('../conv2d_w3/taps_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w3_taps = np.reshape(w3_taps,(3,3,16,64))\n",
    "w3_bias = ((np.loadtxt('../conv2d_w3/bias_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w5_taps = ((np.loadtxt('../conv2d_w5/taps_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w5_taps = np.reshape(w5_taps,(3,3,64,128))\n",
    "w5_bias = ((np.loadtxt('../conv2d_w5/bias_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w7_taps = ((np.loadtxt('../dense_w7/taps_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "w7_taps = np.reshape(w7_taps,(1152,10))\n",
    "w7_bias = ((np.loadtxt('../dense_w7/bias_trained.txt')).astype(\"bfloat16\")).astype(\"float32\")\n",
    "model.set_weights((w1_taps,w1_bias,w3_taps,w3_bias,w5_taps,w5_bias,w7_taps,w7_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ceaf7-750a-4984-a165-8da2e1a6bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905bc81-af38-4280-ae38-072b9530e565",
   "metadata": {},
   "source": [
    "## Load NMIST Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841caa23-3f4f-455a-b21b-06a3b7cece28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size and # of batches\n",
    "BS=1\n",
    "NB_tst = 12  # Must be multiple of 4\n",
    "# Load MNIST database:\n",
    "(trn_images,trn_labels), (tst_images,tst_labels) = mnist.load_data()\n",
    "tst_images = tst_images.reshape((10000,28,28,1))\n",
    "tst_images = tst_images[:NB_tst*BS,:,:,:]\n",
    "# Extract usable data:\n",
    "tst_labels = tst_labels[:NB_tst*BS]\n",
    "tst_images = tst_images.astype(\"float32\") / 255\n",
    "tst_images = (tst_images.astype(\"bfloat16\")).astype(\"float32\")\n",
    "with open(\"num_iter.h\",\"w\") as fid:\n",
    "    fid.write('//\\n')    \n",
    "    fid.write('// Copyright (C) 2024, Advanced Micro Devices, Inc. All rights reserved.\\n')    \n",
    "    fid.write('// SPDX-License-Identifier: MIT\\n')    \n",
    "    fid.write('//\\n')    \n",
    "    fid.write('//  Author: Mark Rollins\\n')    \n",
    "    fid.write(f'#define NUM_ITER {NB_tst/4:5.0f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf2899-8424-4f34-b305-dea322001c7c",
   "metadata": {},
   "source": [
    "## Compute Golden Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9057d8c-3fc2-4574-af17-4d6bc19cc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(tst_images,batch_size=1)\n",
    "predict = (predict.astype(\"bfloat16\")).astype(\"float32\")\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588f848-eb35-409a-94c0-9b9bf986383f",
   "metadata": {},
   "source": [
    "## Store Layer Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1f04f-7eca-4694-906f-245a9001fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save input images for the network:\n",
    "print(tst_images.shape)\n",
    "np.savetxt('data/ifm_i.txt',np.reshape(tst_images,(-1,4)),fmt='%f %f %f %f')\n",
    "ifm_i = np.reshape(tst_images,(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae9119-15e3-49ce-9ef8-ffab0c9ec411",
   "metadata": {},
   "source": [
    "## Store Layer Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de799f89-ecbe-4480-9dcf-3bb4e5402546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict.shape)\n",
    "np.savetxt('data/ofm_o.txt',np.reshape(predict,(-1,4)),fmt='%f %f %f %f')\n",
    "ofm_o = np.reshape(predict,(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470b695-bd02-4596-84a8-8eee71515fac",
   "metadata": {},
   "source": [
    "## Store Weights & Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c3a7f-2fce-4bf1-8e36-234af8001ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taps = np.concatenate((np.reshape(w1_taps,(-1,1)),np.reshape(w1_bias,(-1,1))),axis=0)\n",
    "np.savetxt('data/wts1_i.txt',np.reshape(taps,(-1,4)),fmt='%f %f %f %f')\n",
    "wts1_i = np.reshape(taps,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b748a2-cf52-41eb-a076-dff7ab8c9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "taps = np.concatenate((np.reshape(w3_taps[:,:,0:8, 0: 4],(-1,1)),np.reshape(w3_taps[:,:,8:16, 0: 4],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8, 4: 8],(-1,1)),np.reshape(w3_taps[:,:,8:16, 4: 8],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8, 8:12],(-1,1)),np.reshape(w3_taps[:,:,8:16, 8:12],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,12:16],(-1,1)),np.reshape(w3_taps[:,:,8:16,12:16],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,16:20],(-1,1)),np.reshape(w3_taps[:,:,8:16,16:20],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,20:24],(-1,1)),np.reshape(w3_taps[:,:,8:16,20:24],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,24:28],(-1,1)),np.reshape(w3_taps[:,:,8:16,24:28],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,28:32],(-1,1)),np.reshape(w3_taps[:,:,8:16,28:32],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,32:36],(-1,1)),np.reshape(w3_taps[:,:,8:16,32:36],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,36:40],(-1,1)),np.reshape(w3_taps[:,:,8:16,36:40],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,40:44],(-1,1)),np.reshape(w3_taps[:,:,8:16,40:44],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,44:48],(-1,1)),np.reshape(w3_taps[:,:,8:16,44:48],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,48:52],(-1,1)),np.reshape(w3_taps[:,:,8:16,48:52],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,52:56],(-1,1)),np.reshape(w3_taps[:,:,8:16,52:56],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,56:60],(-1,1)),np.reshape(w3_taps[:,:,8:16,56:60],(-1,1)),\n",
    "                       np.reshape(w3_taps[:,:,0:8,60:64],(-1,1)),np.reshape(w3_taps[:,:,8:16,60:64],(-1,1))),axis=0)\n",
    "taps = np.concatenate((np.reshape(taps,(-1,1)),np.reshape(w3_bias,(-1,1))),axis=0)\n",
    "np.savetxt('data/wts3_i.txt',np.reshape(taps,(-1,4)),fmt='%f %f %f %f')\n",
    "wts3_i = np.reshape(taps,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098d034-2941-4211-a089-a83e66822425",
   "metadata": {},
   "outputs": [],
   "source": [
    "taps = np.reshape(w5_taps,(3,3,8,8,32,4))\n",
    "taps = np.transpose(taps,(4,2,0,1,3,5))\n",
    "taps0 = np.concatenate((np.reshape(taps[ 0: 8,:,:,:,:,:],(-1,1)),np.reshape(w5_bias[ 0: 32],(-1,1))),axis=0);\n",
    "taps1 = np.concatenate((np.reshape(taps[ 8:16,:,:,:,:,:],(-1,1)),np.reshape(w5_bias[32: 64],(-1,1))),axis=0);\n",
    "taps2 = np.concatenate((np.reshape(taps[16:24,:,:,:,:,:],(-1,1)),np.reshape(w5_bias[64: 96],(-1,1))),axis=0);\n",
    "taps3 = np.concatenate((np.reshape(taps[24:32,:,:,:,:,:],(-1,1)),np.reshape(w5_bias[96:128],(-1,1))),axis=0);\n",
    "np.savetxt('data/wts5_0_i.txt',np.reshape(taps0,(-1,4)),fmt='%f %f %f %f')\n",
    "np.savetxt('data/wts5_1_i.txt',np.reshape(taps1,(-1,4)),fmt='%f %f %f %f')\n",
    "np.savetxt('data/wts5_2_i.txt',np.reshape(taps2,(-1,4)),fmt='%f %f %f %f')\n",
    "np.savetxt('data/wts5_3_i.txt',np.reshape(taps3,(-1,4)),fmt='%f %f %f %f')\n",
    "wts5_0_i = np.reshape(taps0,(-1,1))\n",
    "wts5_1_i = np.reshape(taps1,(-1,1))\n",
    "wts5_2_i = np.reshape(taps2,(-1,1))\n",
    "wts5_3_i = np.reshape(taps3,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c05f8b-7d56-4bba-a01f-da5562f20d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to zero-pad weights by 6 for DM alignment & 64-bit PLIO\n",
    "taps = np.reshape(w7_taps,(1152,10))\n",
    "taps = np.transpose(taps,(1,0))\n",
    "taps = np.concatenate((np.reshape(taps,(-1,1)),np.reshape(w7_bias,(-1,1))),axis=0)\n",
    "taps = np.concatenate((taps,np.zeros((6,1))),axis=0)\n",
    "np.savetxt('data/wts7_i.txt',np.reshape(taps,(-1,4)),fmt='%f %f %f %f')\n",
    "wts7_i = np.reshape(taps,(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef232a2-aa06-43e0-b61f-4bc619f14885",
   "metadata": {},
   "source": [
    "## Run Vitis Functional Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747eab2-9a0c-4f52-86ae-31870b479b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vfs\n",
    "mnist_graph = vfs.aieGraph(\n",
    "    input_file='mnist_app.cpp',\n",
    "    part=\"xcve2802-vsvh1760-2MP-e-S\",\n",
    "    include_paths=['./','../wts_init','../conv2d_w1','../conv2d_w3','../conv2d_w5',\n",
    "                  '../max_pooling2d_w2','../max_pooling2d_w4','../dense_w7'])\n",
    "act_o = mnist_graph.run(vfs.array(ifm_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts1_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts3_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts5_0_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts5_1_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts5_2_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts5_3_i[:,0],vfs.bfloat16),\n",
    "                        vfs.array(wts7_i[:,0],vfs.bfloat16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe868a8c-17ba-4628-9050-e451483669fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_o = np.array(act_o)\n",
    "act_o = np.transpose(np.reshape(act_o,(-1,16)),(0,1))\n",
    "ofm_o = np.transpose(np.reshape(ofm_o,(-1,10)),(0,1))\n",
    "act_o = act_o[:,:10]   # Remove zero pad\n",
    "tmp = np.reshape(ofm_o,(-1,1))\n",
    "error = np.reshape(act_o-ofm_o,(-1,1))\n",
    "lvl = np.max(np.abs(tmp))\n",
    "lvl_min = -(0.5**8)*lvl*np.ones((len(tmp),1))\n",
    "lvl_max = +(0.5**8)*lvl*np.ones((len(tmp),1))\n",
    "tt = np.arange(0,len(tmp))\n",
    "fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "ax[0].plot(tt,error,color=\"b\")\n",
    "ax[0].plot(tt,lvl_min,color=\"r\")\n",
    "ax[0].plot(tt,lvl_max,color=\"r\")\n",
    "ax[0].set_title(\"Error: Keras vs. AIE\")\n",
    "ax[1].plot(tt,np.reshape(ofm_o,(-1,1)))\n",
    "ax[1].plot(tt,np.reshape(act_o,(-1,1)),linestyle=\"dashed\")\n",
    "ax[1].set_title(\"ConvNet Outputs\")\n",
    "ax[1].legend(labels=(\"Keras\",\"AIE\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac086696-3026-4016-98a0-2276cd62f454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
